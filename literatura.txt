LITERATURA, state of the art:
	streszczanie dokumentów można podzielić na:
	- ekstrakcyjne(extractive) - wyciąganie fragmentów tekstu z dokumentu, które uznamy za ważne.
	- abstrakcyjne(abstractive) - w oparciu o zrozumienie dokumentu, piszemy nowe zdania, które dobrze oddają esencję dokumentu.
	
	Przed erą AI, streszczanie skupiało się na 1 metodzie, natomiast w przypadku dokumentów prawnych, którą są długie, 
	złożone i napisane formalnym językiem, takie podejście nie sprawdzało się najlepiej, ponieważ streszczenia takie ciągle musiały być długie
	i formalne co jest troche zaprzeczeniem streszczenia. Jako zaletę tego podejścia, niekórzy argumentują, że dokumenty prawne są skomplikowane,
	więc nie da się bez ekstrakcyjnego streszczenia w pełni oddać ich znaczenia. Tutaj warto zaznaczyć różnice w dokumentach prawnych. Ja w swojej pracy
	chcę skupić się na dokumentach prawniczych - to są dokumenty pisane przez strony sporu sądowego oraz sam sąd w trakcie sprawy. Są one tylko 
	podzbiorem dokumentów prawnych, tak więc widząc, że jakieś rozwiązanie działa na dokumentach prawnych (legal documents), nie oznacza
	to, że rozwiązania te działają na dokumentach sądowych/prawniczych. Często tak jak wymieniam poniżej, rozwiąznaia działają w obszarze np. dokumentów 
	legislacyjnych, które znacznie różnią się strukturą i treścią. W związku z tym proszę zwrócić uwagę na dobór słów w dalszej części tekstu.
	prawne != prawnicze/sądowe

	Extractive Summarization of Text Using Supervised and Unsupervised Techniques [https://ieeexplore.ieee.org/document/9537883]
	
	Teraz krótko opiszę metody do generowania streszczeń, które pojawiają się w pracach: 
	- Metody ekstrakcyjne, nienadzorowane,  do stosowania ogólnego (streszczania kazdego rodzaju dokumentów), np.: 
		- Reduction - Metoda ta polega na identyfikacji i usuwaniu mniej istotnych fragmentów tekstu, koncentrując się na zachowaniu kluczowych informacji.
		- LexRank - algorytm oparty na grafach, który ocenia znaczenie zdań na podstawie ich centralności w grafie podobieństw.
		- LSA - Analiza ukrytych wymiarów semantycznych polega na dekompozycji macierzy częstości słów w dokumentach za pomocą technik takich jak SVD 
		(Singular Value Decomposition). Pozwala to na identyfikację ukrytych struktur semantycznych i wybór zdań najlepiej reprezentujących główne 
		tematy tekstu.
		- PacSum - Metoda ta wykorzystuje model BERT do reprezentacji zdań, a następnie buduje graf podobieństw między nimi.
	- Metody ekstrakcyjne, nadzorowane,  do stosowania ogólnego, np.:
		- SummaRunner - Jest to model rekurencyjnej sieci neuronowej (RNN), który traktuje streszczanie jako zadanie sekwencyjnej klasyfikacji. 
		Model uczy się przewidywać, które zdania powinny zostać uwzględnione w streszczeniu.
		- BERTSum - Rozszerzenie modelu BERT dostosowane do zadań streszczania ekstrakcyjnego. Model ten klasyfikuje każde zdanie jako 
		odpowiednie lub nieodpowiednie do streszczenia.
	- Metody ekstrakcyjne, nadzorowane, specjalne dla dokumentów prawnych:
		- LetSum - system, który wykorzystuje analizę strukturalną dokumentu, identyfikując kluczowe sekcje i ekstraktując z nich istotne informacje. 
		Metoda ta opiera się na analizie częstości występowania terminów oraz ich rozmieszczeniu w dokumencie, co pozwala na wyodrębnienie najważniejszych 
		zdań do streszczenia.
		- KMM (K-mixture Model) - Polega na budowie modelu rozkładu terminów w dokumencie, bazując na modelu K-mieszanin(probabilistyczny model 
		statystyczny stosowany do reprezentowania złożonych rozkładów danych poprzez kombinację kilku prostszych rozkładów, najczęściej rozkładów normalnych).
		Model ten jest następnie wykorzystywany do generowania streszczenia poprzez wybór zdań, które najlepiej reprezentują główne tematy dokumentu
		- Gist - Proces rozpoczyna się od reprezentacji każdego zdania za pomocą różnych cech, takich jak długość zdania, pozycja w dokumencie czy częstość 
		występowania terminów. Następnie wykorzystuje trzy modele: wielowarstwowy perceptron (MLP), gradientowe drzewa decyzyjne oraz LSTM, które klasyfikują
		 zdania pod kątem ich przydatności do streszczenia.
	- Metody abstrakcyjne, opierają się o modele AI:
		- Pointer-Generator - Model ten łączy mechanizm generowania z mechanizmem wskazywania (pointer), co pozwala na kopiowanie słów bezpośrednio z tekstu 
		źródłowego oraz generowanie nowych słów. Dzięki temu model radzi sobie z problemem słów spoza słownika (OOV) i redukuje powtarzanie fraz.
		[https://arxiv.org/abs/1704.04368]
		- BERTSumABS - Rozszerzenie modelu BERT dostosowane do zadań streszczania abstrakcyjnego. Model ten wykorzystuje pretrenowany BERT jako enkoder 
		w architekturze typu encoder-decoder, co pozwala na generowanie streszczeń poprzez dekodowanie zakodowanych reprezentacji tekstu źródłowego.
		- Pegasus - Model pretrenowany specjalnie do zadań streszczania, wykorzystujący technikę Gap Sentence Generation (GSG). 
		W trakcie pretrenowania model uczy się przewidywać brakujące zdania w tekście, co zbliża zadanie pretrenowania do rzeczywistego 
		zadania streszczania.[https://huggingface.co/docs/transformers/model_doc/pegasus]
		- BART -  Model typu encoder-decoder, który łączy cechy modeli autoregresyjnych i autoenkoderów. BART jest pretrenowany 
		poprzez rekonstrukcję zniekształconych wejść, co czyni go efektywnym w zadaniach generacyjnych, takich jak streszczanie.
		- Longformer - Model zaprojektowany do przetwarzania długich dokumentów poprzez wprowadzenie mechanizmu uwagi (attention), który skaluje się liniowo 
		z długością sekwencji. Longformer łączy lokalną uwagę okienkową z globalną uwagą, co pozwala na efektywne przetwarzanie dokumentów 
		zawierających tysiące tokenów. [https://huggingface.co/docs/transformers/model_doc/longformer]


	Nie znalazłem, żadnej pracy operującej na polskich dokumentach prawnych w zakresie streszczania lub generowania. 
	Znalazłem natomiast pracę o klasyfikacji orzeczeń sądów [https://www.mdpi.com/1424-8220/22/6/2137] napisaną między innymi przez profesora 
	PW - Roberta Nowaka. Bazuje ona na zbiorze zanonimizowanych orzeczeń publikowanych przez sądy. Niestety zawiera ona jedynie wyroki bez 
	wcześniejszych pism z obu stron. Idąc tym tropem szukałem publicznych, rządowych baz, pytając rówież osoby z branży, jednak nie istnieje 
	żadna publiczna baza zawierająca polskie pisma prawnicze.

	W pracy Automatic Summarization of Legal Text[https://studenttheses.uu.nl/handle/20.500.12932/34261] 
	wytrenowano wlasny model NLP do dokumentow w języku holenderskim. Jako metryk użyto streszczeń porównawczych i metyk ROUGE. Przeprowadzono też 
	eksperyment, w którym ludzie studiujący prawo mieli ocenić jakość tych streszczań. Najpierw studenci czytali i zaznajamiali się z dokumentem, 
	potem oceniali streszczenia, w tym te wygrnerowane przez model i oceniali w skali od 1 do 10 trafność i czytelność. Wyniki pokazywały, że
	model często nie uwzględnia w streszczeniu ważnych informacji, oraz popełnia blędy składniowe.

	W pracy Legal Case Document Summarization: Extractive and Abstractive Methods and their Evaluation[https://aclanthology.org/2022.aacl-main.77.pdf]
	naukowcy wskazują podobne problemy, które ja również napotykam - trudność w użyciu nadzorowanego uczenia, dlatego iż ciężko o duże ilości streszczeń 
	napisanych przez prawników, co sprawia, że zbiory danych są bardzo małe. Dodatkowo wskazują oni na to, że streszczania dokumentów prawniczych są dłuższe niż 
	w przypadku innych dokumentów, ponieważ są one bardziej skomplikowane. W pracy użyto zbiorów wyroków sądów najwyższych w Indiach i Wielkiej Brytanii
	oraz ich streszczeń napisanych przez profesjonalistów. Praca porówuje metody ekstrakcyjne i abstrakcyjne, zarówno nadzrorowane jak i nie. Naukowcy wskazują
	kolejny problem, który pojawia się przy długich dokumentach, mianowicie nie mieszczą się one w wejściu modelu, w związku z tym proponują oni 
	2 podejścia: segmentacja tekstu oraz najpierw streszczenie ekstrakcyjne i potem streszczenie abstrakcyjne na podstawie ekstrakcyjnego. 

	
	
	

